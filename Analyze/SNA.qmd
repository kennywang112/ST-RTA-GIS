---
title: "SNA"
format: html
editor: visual
---

```{r}
getwd()
```

## Social Network Analysis

This is to get the eigen centrality and betweenness

```{r}

source('../utils/model.R')

adj_matrix <- Mapper$adjacency

adj_list <- lapply(1:Mapper$num_vertices, function(i) {
  neighbors <- which(adj_matrix[i, ] > 0)
  return(neighbors[neighbors != i]) # 移除自己
})
# find total unique indices
uniq_idx <- sort(unique(unlist(Mapper$points_in_vertex, use.names = FALSE)))
length(uniq_idx) == dim(all_features)[1]

## Betweenness and Eigenvector Centrality
g <- graph_from_adjacency_matrix(Mapper$adjacency, mode = "undirected")
e_result <- eigen_centrality(g)
e_scores <- e_result$vector
b_scores <- betweenness(g, weights = NA, normalized = TRUE)

# 找橋樑
top_nodes <- sort(b_scores, decreasing = TRUE)
print(head(top_nodes, 10))

b_labels <- rep(0, length(b_scores))
top_10_indices <- head(order(b_scores, decreasing = TRUE), 10)
b_labels[top_10_indices] <- 1
e_labels <- rep(0, length(e_scores))
top_10_eigen_indices <- head(order(e_scores, decreasing = TRUE), 10)
e_labels[top_10_eigen_indices] <- 1
```

This is for adding weighting for eigen centrality edges

```{r}

node_sizes <- pmax(sapply(Mapper$points_in_vertex, length), 1)
g <- graph_from_adjacency_matrix(Mapper$adjacency, mode = "undirected")

calc_edge_weight <- function(u, v) {
  size_u <- node_sizes[u]
  size_v <- node_sizes[v]
  # the weight is inversely proportional to the sum of node sizes
  # because larger nodes should have less influence on betweenness
  return(1 / (size_u + size_v))
}

edge_list <- as_edgelist(g, names = FALSE)
edge_weights <- apply(edge_list, 1, function(x) calc_edge_weight(x[1], x[2]))

b_scores_weighted <- betweenness(g, weights = edge_weights, normalized = TRUE)

MapperPlotterV2(
  Mapper,
  label = b_scores_weighted,
  data = filter_data,
  is_node_attribute = TRUE
)
```

## Mapper algorithm plot

```{r}


source('./Analyze/SNAplot.R')
MapperPlotterV2(
  Mapper,
  # label = e_scores,
  label = e_labels,
  # label = b_labels,
  # label = b_scores,
  data = filter_data,
  is_node_attribute = TRUE
)
MapperPlotterV2(
  Mapper,
  # label = all_features$hotspot,
  label = all_features$bn_feature,
  data = filter_data,
  avg=TRUE,
  is_node_attribute = FALSE
)

```

Save plot

```{r}

cc <- tibble(
  eigen_centrality = e_scores,
  betweenness = b_scores,
)

library(jsonlite)
export_data <- list(
  adjacency = Mapper$adjacency,
  num_vertices = Mapper$num_vertices,
  level_of_vertex = Mapper$level_of_vertex,
  points_in_vertex = Mapper$points_in_vertex,
  original_data = as.data.frame(all_features),
  # this is the label that already calculated for each node
  cc = cc
)

write(toJSON(export_data, auto_unbox = TRUE), "~/desktop/my_mapper_graph.json")
```

Get node features

```{r}

length(g)
length(e_scores)
features <- tibble(
  size = node_sizes <- sapply(Mapper$points_in_vertex, length),
  eigen_centrality = e_scores,
  betweenness = b_scores,
  neighbors = adj_list, # neighbor vertex indices
  points_in_vertex = Mapper$points_in_vertex # original data indices in each vertex
)

# all_features <- read_csv("../ST-RTA/ComputedDataV4/ForModel/all_features.csv")
grid_filter <- read_csv("../../ST-RTA/ComputedDataV2/Grid/grid_filter.csv")$accident_indices
combined_data <- read_csv("../../ST-RTA/ComputedDataV2/Grid/combined_data.csv")
all_features_grid <- cbind(all_features, grid_filter)

filter_features <- features%>%
  mutate(
    neighbor_points = map(neighbors, function(nbr_ids) {
      # get all points in neighbor vertices
      points_list <- points_in_vertex[nbr_ids]
      all_nbr_points <- unlist(points_list)
      unique(all_nbr_points)
    }),
    # count of neighbor points
    neighbor_point_size = sapply(neighbor_points, length),
    # count of neighbor nodes
    neighbor_node_size = sapply(adj_list, length)
  )%>%
  filter(!map_lgl(neighbor_points, is.null))
```

correlation plot

```{r}
# correlation plot
library(GGally)
ggpairs(filter_features,
        columns = c("size", "eigen_centrality", "betweenness",
                    "neighbor_point_size", "neighbor_node_size"),
        upper = list(continuous = wrap("cor", method = "spearman")))
```

# Model

This block show the logistic regression and tree model to fit:

1.  betweenness VS rest data
2.  eigen centrality VS rest data

The result is aroud 0.5, very bad

```{r}

cols <- c(
  '車道劃分設施-分道設施-快車道或一般車道間名稱',
  '車道劃分設施-分道設施-快慢車道間名稱',
  '車道劃分設施-分道設施-路面邊線名稱',
  '車道劃分設施-分向設施大類別名稱',
  '事故類型及型態大類別名稱',
  '道路型態大類別名稱',
  '號誌-號誌種類名稱',
  '速限-第1當事者',
  'youbike_100m_count',
  'mrt_100m_count',
  'parkinglot_100m_count',
  '當事者區分-類別-大類別名稱-車種',
  'cause_group',
  'type'
)

source('./utils/model.R')
# Analyze betweenness top 10 nodes
bdt <- get_model_data(filter_features, betweenness, top_k = 10)
betweenness_info <- model_from_node(bdt[[1]], bdt[[2]], cols)
# betweenness_tree <- tree_model_from_node(bdt[[1]], bdt[[2]], cols, cp_value=0.001)
betweenness_info$accuracy
betweenness_info$confusion_matrix

betweenness_info$importance_df%>%
  filter(Importance > 1.96)%>%
  ggplot(aes(x = Importance, y = Variable, color = Direction)) +
  geom_segment(aes(x = 0, xend = Importance, y = Variable, yend = Variable), linewidth = 1) +
  geom_point(size = 4) +
  scale_color_manual(values = c("Positive" = "#E41A1C", "Negative" = "#377EB8")) +
  theme_minimal()

betweenness_info$top_group

# Analyze eigen_centrality top 10 nodes
edt <- get_model_data(filter_features, eigen_centrality, top_k = 10)
eigen_info <- model_from_node(edt[[1]], edt[[2]], cols)
# eigen_tree <- tree_model_from_node(edt[[1]], edt[[2]], cols, cp_value=0.002)
eigen_info$accuracy

eigen_info$importance_df%>%
  filter(Importance > 1.96)%>%
  ggplot(aes(x = Importance, y = Variable, color = Direction)) +
  geom_segment(aes(x = 0, xend = Importance, y = Variable, yend = Variable), linewidth = 1) +
  geom_point(size = 4) +
  scale_color_manual(values = c("Positive" = "#E41A1C", "Negative" = "#377EB8")) +
  theme_minimal()


betweenness_info$importance_df$type <- 'betwenness'
eigen_info$importance_df$type <- 'eigen_centrality'
fdt <- rbind(betweenness_info$importance_df, eigen_info$importance_df)%>%
  filter(Importance > 1.96)
fdt
```
