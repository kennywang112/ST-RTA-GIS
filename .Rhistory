return(balanced_df)
}
us_data_for_tree <- final_data_for_tree%>%select(-hotspot, -cols_to_remove, -no_lane, -bn_feature, -lr_feature)
final_data_for_tree
final_data_for_tree <- get_four_categories_data(df, final_all_features)
final_data_for_tree <- final_data_for_tree %>%
mutate(Group_Label = recode(Group_Label,
"Hot_with_Safe_Neighbors_highbetweenness" = "Broken",
"Cold_with_Hot_Neighbors_highbetweenness" = "Resilient"
))
table(final_data_for_tree$Group_Label)
final_data_for_tree
do_undersampling <- function(
df, group1_name, group2_name
) {
data_g1 <- df %>% filter(Group_Label == group1_name)
data_g2 <- df %>% filter(Group_Label == group2_name)
n_g1 <- nrow(data_g1)
n_g2 <- nrow(data_g2)
cat(sprintf("原始數量 -> %s: %d, %s: %d\n", group1_name, n_g1, group2_name, n_g2))
target_n <- min(n_g1, n_g2)
set.seed(123)
data_g1_balanced <- data_g1 %>% sample_n(target_n)
data_g2_balanced <- data_g2 %>% sample_n(target_n)
balanced_df <- bind_rows(data_g1_balanced, data_g2_balanced)
cat(sprintf("平衡後數量 -> 各 %d 筆 (總共 %d 筆)\n", target_n, nrow(balanced_df)))
return(balanced_df)
}
us_data_for_tree <- final_data_for_tree%>%select(-hotspot, -cols_to_remove, -no_lane, -bn_feature, -lr_feature)
cols_to_remove
final_data_for_tree
existing_cols <- intersect(names(all_features), names(col_translation))
names(all_features)[match(existing_cols, names(all_features))] <- col_translation[existing_cols]
all_features
adj_matrix <- Mapper$adjacency
adj_list <- lapply(1:Mapper$num_vertices, function(i) {
neighbors <- which(adj_matrix[i, ] > 0)
return(neighbors[neighbors != i])
})
# find total unique indices
uniq_idx <- sort(unique(unlist(Mapper$points_in_vertex, use.names = FALSE)))
length(uniq_idx) == dim(all_features)[1]
## Betweenness and Eigenvector Centrality
g <- graph_from_adjacency_matrix(Mapper$adjacency, mode = "undirected")
e_result <- eigen_centrality(g)
e_scores <- e_result$vector
b_scores <- betweenness(g, weights = NA, normalized = TRUE)
# 找橋樑
top_nodes <- sort(b_scores, decreasing = TRUE)
b_labels <- rep(0, length(b_scores))
top_10_indices <- head(order(b_scores, decreasing = TRUE), 10)
b_labels[top_10_indices] <- 1
e_labels <- rep(0, length(e_scores))
top_10_eigen_indices <- head(order(e_scores, decreasing = TRUE), 10)
e_labels[top_10_eigen_indices] <- 1
# MapperCorrelation(Mapper, original_data = filter_data, labels = list(all_features$bn_feature, all_features$hotspot), use_embedding = list(FALSE, FALSE))
length(g)
length(e_scores)
features <- tibble(
size = node_sizes <- sapply(Mapper$points_in_vertex, length),
eigen_centrality = e_scores,
betweenness = b_scores,
neighbors = adj_list, # neighbor vertex indices
points_in_vertex = Mapper$points_in_vertex # original data indices in each vertex
)
all_features_grid <- cbind(all_features, grid_filter)
node_hotspot_values <- vapply(Mapper$points_in_vertex, function(idx) {
mean(all_features$hotspot[idx], na.rm = TRUE)
}, numeric(1))
features$hotspot <- node_hotspot_values
features <- features%>%mutate(hotspott = ifelse(hotspot > 0.2, 1, 0))
filter_features <- features%>%
mutate(
neighbor_points = map(neighbors, function(nbr_ids) {
# get all points in neighbor vertices
points_list <- points_in_vertex[nbr_ids]
all_nbr_points <- unlist(points_list)
unique(all_nbr_points)
}),
# count of neighbor points
neighbor_point_size = sapply(neighbor_points, length),
# count of neighbor nodes
neighbor_node_size = sapply(adj_list, length)
)%>%
filter(!map_lgl(neighbor_points, is.null))
hotspot_threshold <- 0.5
df <- features %>% mutate(is_hotspot = hotspot > hotspot_threshold)
df <- df %>%
# check if there's hot or safe neighbor first
mutate(
neighbor_hotspot_ratio = map_dbl(neighbors, function(idx) {
if(length(idx) == 0) return(0)
mean(df$is_hotspot[idx])}),
has_safe_neighbor = neighbor_hotspot_ratio < 1,
has_hot_neighbor = neighbor_hotspot_ratio > 0)%>%
# check if itself is hot or safe & the neighbor_hotspot_ratio
# set high betweenness threshold
mutate(
node_category = case_when(
is_hotspot == TRUE & has_safe_neighbor == TRUE ~ "Hot_with_Safe_Neighbors",
is_hotspot == FALSE & has_hot_neighbor == TRUE ~ "Cold_with_Hot_Neighbors",
TRUE ~ "Others"
),
is_high_betweenness = betweenness >= quantile(df$betweenness, 0.9)
)%>%
# finally find the interesting point
mutate(
final_category = case_when(
is_hotspot == TRUE & has_safe_neighbor == TRUE & is_high_betweenness == TRUE ~ "Hot_with_Safe_Neighbors_highbetweenness",
is_hotspot == FALSE & has_hot_neighbor == TRUE & is_high_betweenness == TRUE ~ "Cold_with_Hot_Neighbors_highbetweenness",
TRUE ~ "Others"
)
)
table(df$final_category)
# library(sf)
# roads <- st_read(dsn="../CalculatedData/pairs_annot_all_cities.shp")
# # grid_filter <- read_csv("../../ST-RTA/ComputedDataV2/Grid/grid_filter.csv")
# grid_gi <- read_csv("../../ST-RTA/ComputedDataV2/Grid/grid_giV1.csv")%>%
#   filter(num_accidents>0)%>%
#   mutate(index = row_number())
#
# grid_sf <- st_as_sf(grid_gi, wkt = "geometry", crs = 3826)
# roads <- st_transform(roads, 3826)
# joined_data <- st_join(grid_sf, roads, join = st_intersects, left = TRUE)
#
# result <- joined_data %>%
#   group_by(index) %>%
#   summarise(
#     max_spd_dlt = max(spd_dlt, na.rm = TRUE),
#     road_count = n(),
#     num_accidents = first(num_accidents),
#     .groups = "drop"
#   ) %>%
#   mutate(max_spd_dlt = ifelse(is.infinite(max_spd_dlt), 0, max_spd_dlt))
source('../utils/model.R')
final_all_features <- cbind(all_features)#, result$max_spd_dlt)
result_data <- get_comparison_data(df, final_all_features)
result_data%>%
group_by(group_label)%>%
summarize(n())
final_all_features
final_data_for_tree <- get_four_categories_data(df, final_all_features)
final_data_for_tree <- final_data_for_tree %>%
mutate(Group_Label = recode(Group_Label,
"Hot_with_Safe_Neighbors_highbetweenness" = "Broken",
"Cold_with_Hot_Neighbors_highbetweenness" = "Resilient"
))
table(final_data_for_tree$Group_Label)
all_features_mean <- final_data_for_tree %>%
group_by(Group_Label) %>%
summarise(across(where(is.numeric), \(x) mean(x, na.rm = TRUE))) %>%
ungroup()
all_features_mean$Group_Label%>%unique()
comparison_table <- all_features_mean %>%
pivot_longer(
cols = -Group_Label,
names_to = "Feature",
values_to = "Mean_Value"
) %>%
pivot_wider(
names_from = Group_Label,
values_from = "Mean_Value"
)
for (main_group in c("Broken", "Resilient")) {
neighbor_group <- paste0(main_group, "_Neighbors")
overlap_group  <- paste0(main_group, "_Overlap")
group_order <- c(main_group, overlap_group, neighbor_group)
plot_data <- comparison_table %>%
filter(!Feature %in% l, Feature != 'Road Edge Line_Present') %>%
mutate(diff_val = abs(.data[[main_group]] - .data[[neighbor_group]])) %>%
arrange(desc(diff_val)) %>%
head(20) %>%
mutate(Feature = reorder(Feature, diff_val)) %>%
pivot_longer(
cols = -c(Feature, diff_val),
names_to = "Group",
values_to = "Value")%>%
filter(Group %in% group_order) %>%
mutate(Group = factor(Group, levels = group_order))
p <- ggplot(plot_data, aes(x = reorder(Feature, Value), y = Value, fill = Group)) +
geom_col(position = "dodge", width = 0.7) +
coord_flip() +
labs(title = paste(main_group, "Group"), y = "Mean Proportion", x = NULL) +
theme_minimal()
print(p)
}
#| message: false
#| warning: false
source('../AnalyzeV2/MapperforSNA.R')
do_undersampling <- function(
df, group1_name, group2_name
) {
data_g1 <- df %>% filter(Group_Label == group1_name)
data_g2 <- df %>% filter(Group_Label == group2_name)
n_g1 <- nrow(data_g1)
n_g2 <- nrow(data_g2)
cat(sprintf("原始數量 -> %s: %d, %s: %d\n", group1_name, n_g1, group2_name, n_g2))
target_n <- min(n_g1, n_g2)
set.seed(123)
data_g1_balanced <- data_g1 %>% sample_n(target_n)
data_g2_balanced <- data_g2 %>% sample_n(target_n)
balanced_df <- bind_rows(data_g1_balanced, data_g2_balanced)
cat(sprintf("平衡後數量 -> 各 %d 筆 (總共 %d 筆)\n", target_n, nrow(balanced_df)))
return(balanced_df)
}
us_data_for_tree <- final_data_for_tree%>%select(-hotspot, -cols_to_remove, -no_lane, -bn_feature, -lr_feature)
bad_group_balanced <- do_undersampling(
us_data_for_tree,
"Broken",# Hot_with_Safe_Neighbors_highbetweenness
"Broken_Neighbors"
)
res_group_balanced <- do_undersampling(
us_data_for_tree,
"Resilient", # Cold_with_Hot_Neighbors_highbetweenness
"Resilient_Neighbors"
)
#| message: false
#| warning: false
tree_bad_model <- rpart(Group_Label ~ . ,
data = bad_group_balanced,
method = "class",
maxdepth = 5,
control = rpart.control(cp = 0.01),
parms = list(prior = c(0.5, 0.5))
)
pred_class <- predict(tree_bad_model, newdata = bad_group_balanced, type = "class")
conf_matrix <- confusionMatrix(data = pred_class, reference = as.factor(bad_group_balanced$Group_Label))
print(conf_matrix)
png("../Layouts/tree_bad_model.png", width = 1200, height = 800)
# rpart.plot(tree_bad_model, family = "PingFang", tweak = 1.5)
rpart.plot(tree_bad_model,
type = 4,
extra = 106,
under = TRUE,
fallen.leaves = FALSE,
box.palette = "BuGn",
# shadow.col = "gray",
nn = TRUE,
tweak = 1.1,
# varlen = 0,
# faclen = 0,
)
dev.off()
# rpart.plot(tree_bad_model, family = "PingFang", tweak = 1.5)
rpart.plot(tree_bad_model,
type = 4,
extra = 106,
under = TRUE,
fallen.leaves = FALSE,
box.palette = "BuGn",
# shadow.col = "gray",
nn = TRUE,
tweak = 1.1,
# varlen = 0,
# faclen = 0,
)
tree_res_model <- rpart(Group_Label ~ . ,
data = res_group_balanced,
method = "class",
maxdepth = 5,
control = rpart.control(cp = 0.01),
parms = list(prior = c(0.5, 0.5))
)
pred_class <- predict(tree_res_model, newdata = res_group_balanced, type = "class")
conf_matrix <- confusionMatrix(data = pred_class, reference = as.factor(res_group_balanced$Group_Label))
print(conf_matrix)
png("../Layouts/tree_res_model.png", width = 1200, height = 900, res = 300)
rpart.plot(tree_res_model,
type = 4,
extra = 106,
under = TRUE,
fallen.leaves = FALSE,
box.palette = "BuGn",
# shadow.col = "gray",
nn = TRUE,
tweak = 1.1,
# varlen = 0,
# faclen = 0,
)
dev.off()
bad_group_balanced
#| message: false
#| warning: false
tree_bad_model <- rpart(Group_Label ~ . ,
data = bad_group_balanced,
method = "class",
maxdepth = 5,
control = rpart.control(cp = 0.01),
parms = list(prior = c(0.5, 0.5))
)
pred_class <- predict(tree_bad_model, newdata = bad_group_balanced, type = "class")
conf_matrix <- confusionMatrix(data = pred_class, reference = as.factor(bad_group_balanced$Group_Label))
print(conf_matrix)
png("../Layouts/tree_bad_model.png", width = 1200, height = 800)
# rpart.plot(tree_bad_model, family = "PingFang", tweak = 1.5)
rpart.plot(tree_bad_model,
type = 4,
extra = 106,
under = TRUE,
fallen.leaves = FALSE,
box.palette = "BuGn",
# shadow.col = "gray",
nn = TRUE,
tweak = 1,
# varlen = 0,
# faclen = 0,
)
dev.off()
do_undersampling <- function(
df, group1_name, group2_name
) {
data_g1 <- df %>% filter(Group_Label == group1_name)
data_g2 <- df %>% filter(Group_Label == group2_name)
n_g1 <- nrow(data_g1)
n_g2 <- nrow(data_g2)
cat(sprintf("原始數量 -> %s: %d, %s: %d\n", group1_name, n_g1, group2_name, n_g2))
target_n <- min(n_g1, n_g2)
set.seed(123)
data_g1_balanced <- data_g1 %>% sample_n(target_n)
data_g2_balanced <- data_g2 %>% sample_n(target_n)
balanced_df <- bind_rows(data_g1_balanced, data_g2_balanced)
cat(sprintf("平衡後數量 -> 各 %d 筆 (總共 %d 筆)\n", target_n, nrow(balanced_df)))
return(balanced_df)
}
top_betweenness
filter_features
betweenness
bdt <- get_model_grid(filter_features, betweenness, top_k = 10)
edt <- get_model_grid(filter_features, eigen_centrality, top_k = 10)
top_betweenness <- bdt[[1]]
top_eigen <- edt[[1]]
common_nodes <- inner_join(top_betweenness, top_eigen)
betweenness_only <- anti_join(top_betweenness, top_eigen)
eigen_only <- anti_join(top_eigen, top_betweenness)
dim(betweenness_only)[1] + dim(common_nodes)[1] == dim(top_betweenness)[1] &
dim(eigen_only)[1] + dim(common_nodes)[1] == dim(top_eigen)[1]
source('./utils/model.R')
###########
top_betweenness$type <- 1
top_eigen$type <- 0
n_between <- nrow(betweenness_only)
n_eigen <- nrow(eigen_only)
target_size <- min(n_between, n_eigen)
fdt <- bind_rows(
top_betweenness %>% sample_n(target_size),
top_eigen %>% sample_n(target_size)
)%>%select(-bn_feature, -grid_filter, -hotspot, -all_of(cols_to_remove))
fdt
fdt <- bind_rows(
top_betweenness %>% sample_n(target_size),
top_eigen %>% sample_n(target_size)
)%>%select(-bn_feature, -grid_filter, -hotspot, -all_of(cols_to_remove))
top_betweenness
top_betweenness
bdt
#| message: false
#| warning: false
source('../AnalyzeV2/MapperforSNA.R')
set.seed(123)
source('../Analyze/utils.R')
existing_cols <- intersect(names(all_features), names(col_translation))
names(all_features)[match(existing_cols, names(all_features))] <- col_translation[existing_cols]
adj_matrix <- Mapper$adjacency
adj_list <- lapply(1:Mapper$num_vertices, function(i) {
neighbors <- which(adj_matrix[i, ] > 0)
return(neighbors[neighbors != i])
})
# find total unique indices
uniq_idx <- sort(unique(unlist(Mapper$points_in_vertex, use.names = FALSE)))
length(uniq_idx) == dim(all_features)[1]
## Betweenness and Eigenvector Centrality
g <- graph_from_adjacency_matrix(Mapper$adjacency, mode = "undirected")
e_result <- eigen_centrality(g)
e_scores <- e_result$vector
b_scores <- betweenness(g, weights = NA, normalized = TRUE)
# 找橋樑
top_nodes <- sort(b_scores, decreasing = TRUE)
b_labels <- rep(0, length(b_scores))
top_10_indices <- head(order(b_scores, decreasing = TRUE), 10)
b_labels[top_10_indices] <- 1
e_labels <- rep(0, length(e_scores))
top_10_eigen_indices <- head(order(e_scores, decreasing = TRUE), 10)
e_labels[top_10_eigen_indices] <- 1
MapperPlotter(
Mapper,
# label = e_scores,
label = b_scores,
original_data = filter_data,
use_embedding=TRUE
)
MapperPlotter(
Mapper,
label = all_features$hotspot,
# label = all_features$lr_feature,
original_data = filter_data,
avg=TRUE,
use_embedding=FALSE
)
# MapperCorrelation(Mapper, original_data = filter_data, labels = list(all_features$bn_feature, all_features$hotspot), use_embedding = list(FALSE, FALSE))
length(g)
length(e_scores)
features <- tibble(
size = node_sizes <- sapply(Mapper$points_in_vertex, length),
eigen_centrality = e_scores,
betweenness = b_scores,
neighbors = adj_list, # neighbor vertex indices
points_in_vertex = Mapper$points_in_vertex # original data indices in each vertex
)
all_features_grid <- cbind(all_features, grid_filter)
node_hotspot_values <- vapply(Mapper$points_in_vertex, function(idx) {
mean(all_features$hotspot[idx], na.rm = TRUE)
}, numeric(1))
features$hotspot <- node_hotspot_values
features <- features%>%mutate(hotspott = ifelse(hotspot > 0.2, 1, 0))
filter_features <- features%>%
mutate(
neighbor_points = map(neighbors, function(nbr_ids) {
# get all points in neighbor vertices
points_list <- points_in_vertex[nbr_ids]
all_nbr_points <- unlist(points_list)
unique(all_nbr_points)
}),
# count of neighbor points
neighbor_point_size = sapply(neighbor_points, length),
# count of neighbor nodes
neighbor_node_size = sapply(adj_list, length)
)%>%
filter(!map_lgl(neighbor_points, is.null))
library(jsonlite)
export_data <- list(
adjacency = Mapper$adjacency,
num_vertices = Mapper$num_vertices,
level_of_vertex = Mapper$level_of_vertex,
points_in_vertex = Mapper$points_in_vertex,
original_data = as.data.frame(all_features),
# this is the label that already calculated for each node
cc = tibble(
eigen_centrality = e_scores,
betweenness = b_scores,
weighted_betweenness = b_scores_weighted,
weighted_eigen_centrality = e_scores_weighted,
eigen_top10 = e_labels,
betweenness_top10 = b_labels,
threshold_hotspot = features$hotspott
)
)
library(jsonlite)
export_data <- list(
adjacency = Mapper$adjacency,
num_vertices = Mapper$num_vertices,
level_of_vertex = Mapper$level_of_vertex,
points_in_vertex = Mapper$points_in_vertex,
original_data = as.data.frame(all_features),
# this is the label that already calculated for each node
cc = tibble(
eigen_centrality = e_scores,
betweenness = b_scores,
# weighted_betweenness = b_scores_weighted,
# weighted_eigen_centrality = e_scores_weighted,
eigen_top10 = e_labels,
betweenness_top10 = b_labels,
threshold_hotspot = features$hotspott
)
)
features
all_features
all_features <- read_csv("../../ST-RTA/ComputedDataV4/ForModel/all_features.csv")%>%select(-hotspot)
all_features$hotspot <- new_label$hotspot
library(jsonlite)
export_data <- list(
adjacency = Mapper$adjacency,
num_vertices = Mapper$num_vertices,
level_of_vertex = Mapper$level_of_vertex,
points_in_vertex = Mapper$points_in_vertex,
original_data = as.data.frame(all_features),
# this is the label that already calculated for each node
cc = tibble(
eigen_centrality = e_scores,
betweenness = b_scores,
# weighted_betweenness = b_scores_weighted,
# weighted_eigen_centrality = e_scores_weighted,
eigen_top10 = e_labels,
betweenness_top10 = b_labels,
threshold_hotspot = features$hotspott
)
)
write(toJSON(export_data, auto_unbox = TRUE), "~/desktop/ST-RTA-GIS/CalculatedData/Mapper/mapper_graph.json")
all_features
new_label$hotspot%>%table()
####################### save model
all_features$hotspot%>%tible()
####################### save model
all_features$hotspot%>%tibble()
library(jsonlite)
export_data <- list(
adjacency = Mapper$adjacency,
num_vertices = Mapper$num_vertices,
level_of_vertex = Mapper$level_of_vertex,
points_in_vertex = Mapper$points_in_vertex,
original_data = as.data.frame(all_features),
# this is the label that already calculated for each node
cc = tibble(
eigen_centrality = e_scores,
betweenness = b_scores,
# weighted_betweenness = b_scores_weighted,
# weighted_eigen_centrality = e_scores_weighted,
eigen_top10 = e_labels,
betweenness_top10 = b_labels,
threshold_hotspot = features$hotspott
)
)
write(toJSON(export_data, auto_unbox = TRUE), "~/desktop/ST-RTA-GIS/CalculatedData/Mapper/mapper_graph.json")
